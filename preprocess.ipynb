{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import re\n",
    "import joblib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 已经下载了\n",
    "# nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"stop_words.txt\", \"r\", encoding=\"latin1\") as f:\n",
    "    stop_words = f.read().strip().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"mr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param\n",
    "stop_words = set(stopwords.words('english'))\n",
    "least_freq = 5\n",
    "if dataset == \"mr\" or \"SST\" in dataset:\n",
    "    stop_words = set()\n",
    "    least_freq = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# func load texts & labels\n",
    "def load_dataset(dataset):\n",
    "    with open(f\"corpus/{dataset}.texts.txt\", \"r\", encoding=\"latin1\") as f:\n",
    "        texts = f.read().strip().split(\"\\n\")\n",
    "    with open(f\"corpus/{dataset}.labels.txt\", \"r\") as f:\n",
    "        labels = f.read().strip().split(\"\\n\")\n",
    "    return texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_text(text: str):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"([\\w\\.-]+)@([\\w\\.-]+)(\\.[\\w\\.]+)\", \" \", text)  # 删除邮件地址\n",
    "    text = re.sub(r\"([\\w\\.-]+)@([\\w\\.-]+)\", \" \", text)  # 删除邮件地址\n",
    "    text = re.sub(r\"([\\w\\.-]+)(\\.[\\w\\.]+)\", \" \", text)  # 删除网址\n",
    "    text = text.replace(\"'ll \", \" will \")\n",
    "    text = text.replace(\"'d \", \" would \")\n",
    "    text = text.replace(\"'m \", \" am \")\n",
    "    text = text.replace(\"'s \", \" is \")\n",
    "    text = text.replace(\"'re \", \" are \")\n",
    "    text = text.replace(\"'ve \", \" have \")\n",
    "    text = text.replace(\" can't \", \" can not \")\n",
    "    text = text.replace(\" ain't \", \" are not \")\n",
    "    text = text.replace(\"n't \", \" not \")\n",
    "    text = text.replace(\". . .\", \" . \")\n",
    "    text =  re.sub(r\"\\.{2,}\", '.', text)  # 删除多余.\n",
    "    text = re.sub(r'\\.$', '', text.strip())\n",
    "    text = re.sub(r'^\\.', '', text.strip())\n",
    "    text = re.sub(r\"[^A-Za-z0-9,.!?\\'`]\", \" \", text)\n",
    "    text = text.replace(\",\", \" , \")\n",
    "    text = text.replace(\"!\", \" ! \")\n",
    "    text = text.replace(\"?\", \" ? \")\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    return \" \".join(text.strip().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_text(text:str):\n",
    "    pos = text.split()\n",
    "    return nltk.pos_tag(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts, labels = load_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle texts\n",
    "texts_clean = [filter_text(t) for t in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"slackers' jokey approach to college education is disappointingly simplistic the film is biggest problem and there are no unforgettably stupid stunts or uproariously rude lines of dialogue to remember it by\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_clean[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pos = [pos_text(t) for t in texts_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"slackers'\", 'NN'),\n",
       " ('jokey', 'NN'),\n",
       " ('approach', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('college', 'NN'),\n",
       " ('education', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('disappointingly', 'RB'),\n",
       " ('simplistic', 'JJ'),\n",
       " ('the', 'DT'),\n",
       " ('film', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('biggest', 'JJS'),\n",
       " ('problem', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('there', 'EX'),\n",
       " ('are', 'VBP'),\n",
       " ('no', 'DT'),\n",
       " ('unforgettably', 'RB'),\n",
       " ('stupid', 'JJ'),\n",
       " ('stunts', 'NNS'),\n",
       " ('or', 'CC'),\n",
       " ('uproariously', 'RB'),\n",
       " ('rude', 'JJ'),\n",
       " ('lines', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('dialogue', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('remember', 'VB'),\n",
       " ('it', 'PRP'),\n",
       " ('by', 'IN')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pos[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2count = Counter([w for t in texts_clean for w in t.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = [[w, c] for w, c in word2count.items() if c >= least_freq and w not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index = {w: i for i, (w, c) in enumerate(word_count)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_list = [[w for w in t.split() if w in word2index] for t in texts_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"slackers'\",\n",
       " 'jokey',\n",
       " 'approach',\n",
       " 'to',\n",
       " 'college',\n",
       " 'education',\n",
       " 'is',\n",
       " 'disappointingly',\n",
       " 'simplistic',\n",
       " 'the',\n",
       " 'film',\n",
       " 'is',\n",
       " 'biggest',\n",
       " 'problem',\n",
       " 'and',\n",
       " 'there',\n",
       " 'are',\n",
       " 'no',\n",
       " 'unforgettably',\n",
       " 'stupid',\n",
       " 'stunts',\n",
       " 'or',\n",
       " 'uproariously',\n",
       " 'rude',\n",
       " 'lines',\n",
       " 'of',\n",
       " 'dialogue',\n",
       " 'to',\n",
       " 'remember',\n",
       " 'it',\n",
       " 'by']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_list[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_pos_list(texts, text_pos, word2index):\n",
    "    words_list = []\n",
    "    pos_list = []\n",
    "    for t, p in zip(texts, text_pos):\n",
    "        temp = []\n",
    "        temp_pos = []\n",
    "        t_split = t.split()\n",
    "        for i in range(0, len(t_split)):\n",
    "            if t_split[i] in word2index:\n",
    "                temp.append(t_split[i])\n",
    "                temp_pos.append(p[i][1])\n",
    "        words_list.append(temp)\n",
    "        pos_list.append(temp_pos)\n",
    "    return words_list, pos_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list, pos_list = words_pos_list(texts_clean, text_pos, word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NN',\n",
       " 'NN',\n",
       " 'NN',\n",
       " 'TO',\n",
       " 'NN',\n",
       " 'NN',\n",
       " 'VBZ',\n",
       " 'RB',\n",
       " 'JJ',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'VBZ',\n",
       " 'JJS',\n",
       " 'NN',\n",
       " 'CC',\n",
       " 'EX',\n",
       " 'VBP',\n",
       " 'DT',\n",
       " 'RB',\n",
       " 'JJ',\n",
       " 'NNS',\n",
       " 'CC',\n",
       " 'RB',\n",
       " 'JJ',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'NN',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'PRP',\n",
       " 'IN']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_list[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos2count = Counter([w for t in pos_list for w in t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_count = [[w, c] for w, c in pos2count.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos2index = {w: i for i, (w, c) in enumerate(pos_count)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_remove = [\" \".join(ws) for ws in words_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"slackers' jokey approach to college education is disappointingly simplistic the film is biggest problem and there are no unforgettably stupid stunts or uproariously rude lines of dialogue to remember it by\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_remove[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels 2 targets\n",
    "label2index = {l: i for i, l in enumerate(set(labels))}\n",
    "targets = [label2index[l] for l in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['temp/mr.word2index.pkl']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save\n",
    "with open(f\"temp/{dataset}.texts.clean.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(texts_clean))\n",
    "\n",
    "with open(f\"temp/{dataset}.texts.remove.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(texts_remove))\n",
    "\n",
    "np.save(f\"temp/{dataset}.targets.npy\", targets)\n",
    "joblib.dump(word2index, f\"temp/{dataset}.word2index.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
